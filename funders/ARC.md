# Alignment Research Center (ARC)
**Philosophical frame**  
Test assumptions early; surface failure modes.

> Independent adversarial evals that turn safety claims into testable propositions.

**Operational fit**  
Adversarial evals, theory-grounded audits.

**Benefits / ROI**  
- Independent assurance to funders/public bodies  
- Sharper governance metrics and thresholds  
- Counterweights optimistic scaling narratives

**Complementarity & synergy**  
Strengthens credibility of OpenAI-scale experiments; guides SFF deployment; pairs with OSF on accountability.


**Further reading:** [Extended note](/funders/extended/ARC.md)


**Related exemplars:** [OpenAI](/funders/OpenAI.md), [Anthropic](/funders/Anthropic.md), [RedwoodResearch](/funders/RedwoodResearch.md), [GovAI](/funders/GovAI.md), [NIST](/funders/NIST.md)

